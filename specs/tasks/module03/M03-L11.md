# M03-L11: HDC Model (E9 - Custom)

```yaml
task_id: M03-L11
version: 2.0.0
status: complete
layer: logic
sequence: 11
implements: "PRD E9 - HDC embedding with XOR binding and Hamming distance"
depends_on: [M03-F09]
estimated_hours: 4
updated: 2026-01-01
completed: 2026-01-01
verified_by: sherlock-holmes
tests_passed: 52/52
```

---

## CRITICAL CONTEXT FOR IMPLEMENTATION

### What This Task Is
Implement a Hyperdimensional Computing (HDC) embedding model (E9). HDC uses high-dimensional binary vectors (10,000 bits) with XOR binding for composition and Hamming distance for similarity. The 10K-bit vector projects to a 1024D float vector for FuseMoE input.

### Why HDC Matters
- **Symbolic manipulation**: XOR binding enables compositional semantics
- **Noise-robust**: Holographic representation distributes information across all dimensions
- **Low-latency**: No neural network forward pass, pure bit operations (<1ms target)
- **Quasi-orthogonality**: Random high-D vectors are nearly orthogonal by default

### Where It Fits
```
ModelId::Hdc = 8  (E9 in PRD)
├── dimension() → 10000 (raw bit vector)
├── projected_dimension() → 1024 (after projection)
├── is_custom() → true (no pretrained weights)
├── latency_budget_ms() → 1ms
└── max_tokens() → usize::MAX (character-based, not tokenized)
```

---

## FILE LOCATIONS

### Files to Create
```
crates/context-graph-embeddings/src/models/custom/hdc.rs  ← Main implementation
```

### Files to Modify
```
crates/context-graph-embeddings/src/models/custom/mod.rs  ← Add: mod hdc; pub use hdc::*;
```

### Existing Files to Reference (DO NOT MODIFY)
```
crates/context-graph-embeddings/src/types/model_id.rs         ← ModelId::Hdc already defined
crates/context-graph-embeddings/src/traits/embedding_model.rs ← EmbeddingModel trait
crates/context-graph-embeddings/src/error.rs                  ← EmbeddingError enum
crates/context-graph-embeddings/src/types/input.rs            ← ModelInput enum
crates/context-graph-embeddings/src/types/embedding.rs        ← ModelEmbedding struct
crates/context-graph-embeddings/src/models/custom/temporal_*.rs ← Pattern reference
crates/context-graph-embeddings/src/models/pretrained/graph.rs ← Pattern reference
```

---

## EXACT IMPLEMENTATION REQUIREMENTS

### Constants
```rust
/// HDC binary dimension (10,000 bits for quasi-orthogonality)
pub const HDC_BIT_DIMENSION: usize = 10240;  // Must be multiple of 64 for u64 words

/// Output dimension after projection to float
pub const HDC_OUTPUT_DIMENSION: usize = 1024;

/// Latency budget from constitution.yaml
pub const HDC_LATENCY_BUDGET_MS: u64 = 1;

/// Maximum supported characters (HDC processes raw chars, not tokens)
pub const HDC_MAX_CHARS: usize = 4096;

/// Number of position vectors to pre-generate
pub const HDC_POSITION_VECTORS: usize = 512;
```

### Struct Definition
```rust
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::RwLock;

use async_trait::async_trait;
use bitvec::prelude::*;

use crate::error::{EmbeddingError, EmbeddingResult};
use crate::traits::{EmbeddingModel, SingleModelConfig};
use crate::types::{InputType, ModelEmbedding, ModelId, ModelInput};

/// Internal state for HDC model
enum ModelState {
    Unloaded,
    Loaded {
        /// Base hypervectors for each character (random, frozen after init)
        base_vectors: HashMap<char, BitVec<u64, Lsb0>>,
        /// Position encoding vectors for sequence binding
        position_vectors: Vec<BitVec<u64, Lsb0>>,
        /// Projection weights from binary to float (HDC_BIT_DIMENSION → HDC_OUTPUT_DIMENSION)
        projection_weights: Vec<f32>,
    },
}

pub struct HdcModel {
    model_state: RwLock<ModelState>,
    model_path: PathBuf,
    config: SingleModelConfig,
    loaded: AtomicBool,
    /// Seed for deterministic base vector generation
    seed: u64,
}
```

### Required Methods

#### Construction
```rust
impl HdcModel {
    /// Create new HdcModel. NOT loaded after construction - call load() first.
    pub fn new(model_path: &Path, config: SingleModelConfig) -> EmbeddingResult<Self>;

    /// Create with explicit seed for deterministic base vectors
    pub fn with_seed(model_path: &Path, config: SingleModelConfig, seed: u64) -> EmbeddingResult<Self>;
}
```

#### Core HDC Operations (Public Static Methods)
```rust
impl HdcModel {
    /// XOR binding of two hypervectors (commutative, self-inverse)
    /// A XOR B = B XOR A
    /// A XOR A = 0 (all zeros)
    pub fn bind(a: &BitVec<u64, Lsb0>, b: &BitVec<u64, Lsb0>) -> BitVec<u64, Lsb0>;

    /// Majority bundling of multiple hypervectors
    /// For each bit position: 1 if majority of vectors have 1, else 0
    /// Ties broken by 0 (conservative)
    pub fn bundle(vectors: &[BitVec<u64, Lsb0>]) -> BitVec<u64, Lsb0>;

    /// Circular permutation (rotation) for position encoding
    /// Shifts bits right by `positions`, wrapping around
    pub fn permute(v: &BitVec<u64, Lsb0>, positions: usize) -> BitVec<u64, Lsb0>;

    /// Hamming distance between two hypervectors (count of differing bits)
    pub fn hamming_distance(a: &BitVec<u64, Lsb0>, b: &BitVec<u64, Lsb0>) -> usize;

    /// Normalized Hamming similarity (0 to 1)
    /// similarity = 1 - (hamming_distance / dimension)
    pub fn similarity(a: &BitVec<u64, Lsb0>, b: &BitVec<u64, Lsb0>) -> f32;
}
```

#### Internal Methods
```rust
impl HdcModel {
    /// Generate deterministic random base vector for a character
    fn generate_base_vector(c: char, seed: u64) -> BitVec<u64, Lsb0>;

    /// Get or generate base vector for character (lazy initialization)
    fn get_base_vector(&self, c: char) -> EmbeddingResult<BitVec<u64, Lsb0>>;

    /// Encode a single character to its hypervector (from base_vectors)
    fn encode_char(&self, c: char) -> EmbeddingResult<BitVec<u64, Lsb0>>;

    /// Encode string using Holographic Reduced Representation (HRR)
    /// For each char: bind(char_vec, position_vec), then bundle all
    fn encode_string(&self, text: &str) -> EmbeddingResult<BitVec<u64, Lsb0>>;

    /// Project 10K-bit binary vector to 1024D float vector
    /// Groups of 10 bits → mean → scale to [-1, 1]
    fn project_to_float(&self, binary: &BitVec<u64, Lsb0>) -> Vec<f32>;

    /// Extract text content from ModelInput
    fn extract_content(input: &ModelInput) -> EmbeddingResult<String>;
}
```

#### Lifecycle Methods
```rust
impl HdcModel {
    /// Load/initialize base vectors and projection (deterministic from seed)
    pub async fn load(&self) -> EmbeddingResult<()>;

    /// Unload and free memory
    pub async fn unload(&self) -> EmbeddingResult<()>;

    /// Batch embedding
    pub async fn embed_batch(&self, inputs: &[ModelInput]) -> EmbeddingResult<Vec<ModelEmbedding>>;
}
```

### EmbeddingModel Trait Implementation
```rust
#[async_trait]
impl EmbeddingModel for HdcModel {
    fn model_id(&self) -> ModelId { ModelId::Hdc }

    fn supported_input_types(&self) -> &[InputType] { &[InputType::Text, InputType::Code] }

    fn is_initialized(&self) -> bool { self.loaded.load(Ordering::SeqCst) }

    async fn embed(&self, input: &ModelInput) -> EmbeddingResult<ModelEmbedding>;
}
```

---

## ALGORITHM DETAILS

### Holographic Reduced Representation (HRR) for Strings
```rust
fn encode_string(&self, text: &str) -> EmbeddingResult<BitVec<u64, Lsb0>> {
    let chars: Vec<char> = text.chars().take(HDC_MAX_CHARS).collect();
    if chars.is_empty() {
        return Err(EmbeddingError::EmptyInput);
    }

    let state = self.model_state.read().map_err(|e| {
        EmbeddingError::InternalError { message: format!("Lock poisoned: {}", e) }
    })?;

    let ModelState::Loaded { base_vectors, position_vectors, .. } = &*state else {
        return Err(EmbeddingError::NotInitialized { model_id: ModelId::Hdc });
    };

    // Encode each character with position binding
    let encoded: Vec<BitVec<u64, Lsb0>> = chars.iter().enumerate()
        .map(|(pos, &c)| {
            let char_vec = base_vectors.get(&c)
                .cloned()
                .unwrap_or_else(|| Self::generate_base_vector(c, self.seed));
            let pos_vec = &position_vectors[pos % position_vectors.len()];
            Self::bind(&char_vec, pos_vec)
        })
        .collect();

    // Bundle all position-bound characters
    Ok(Self::bundle(&encoded))
}
```

### Majority Bundling
```rust
fn bundle(vectors: &[BitVec<u64, Lsb0>]) -> BitVec<u64, Lsb0> {
    if vectors.is_empty() {
        return bitvec![u64, Lsb0; 0; HDC_BIT_DIMENSION];
    }
    if vectors.len() == 1 {
        return vectors[0].clone();
    }

    let n = vectors.len();
    let threshold = n / 2;  // Ties go to 0

    let mut result = bitvec![u64, Lsb0; 0; HDC_BIT_DIMENSION];

    for i in 0..HDC_BIT_DIMENSION {
        let count = vectors.iter().filter(|v| v[i]).count();
        result.set(i, count > threshold);
    }

    result
}
```

### Binary to Float Projection
```rust
fn project_to_float(&self, binary: &BitVec<u64, Lsb0>) -> Vec<f32> {
    // 10240 bits / 1024 output = 10 bits per output
    let bits_per_output = HDC_BIT_DIMENSION / HDC_OUTPUT_DIMENSION;

    (0..HDC_OUTPUT_DIMENSION)
        .map(|i| {
            let start = i * bits_per_output;
            let end = start + bits_per_output;
            let ones = binary[start..end].count_ones();
            // Scale to [-1, 1]: (ones/bits_per_output) * 2 - 1
            (ones as f32 / bits_per_output as f32) * 2.0 - 1.0
        })
        .collect()
}
```

---

## DEPENDENCIES

### Cargo.toml Additions
```toml
[dependencies]
bitvec = "1.0"  # Efficient bit vector operations
```

Verify bitvec is already in workspace Cargo.toml or add it.

---

## VALIDATION CRITERIA

### Must Pass
1. `cargo check` passes with no errors
2. `cargo test --lib -p context-graph-embeddings` passes all tests
3. `HdcModel::new()` creates valid unloaded instance
4. `load()` initializes deterministic base vectors from seed
5. `embed()` returns 1024D float vector
6. `embed()` returns `NotInitialized` error if not loaded
7. `bind()` is commutative: `bind(A, B) == bind(B, A)`
8. `bind()` is self-inverse: `bind(A, A)` is all zeros
9. `bundle()` produces representative vector (majority vote)
10. `hamming_distance(A, A) == 0`
11. `similarity(A, A) == 1.0`
12. Same seed produces identical base vectors across runs
13. Similar strings have similarity > 0.5
14. Latency < 50ms in stub mode (real target: <1ms)

---

## MANDATORY TESTING REQUIREMENTS

### Unit Tests (Minimum 30 Tests)

#### Construction Tests
- `test_new_creates_unloaded_model`
- `test_new_with_zero_batch_size_fails`
- `test_with_seed_creates_deterministic_model`

#### Trait Implementation Tests
- `test_model_id_is_hdc`
- `test_dimension_is_10000`
- `test_projected_dimension_is_1024`
- `test_max_tokens_is_usize_max`
- `test_latency_budget_ms_is_1`
- `test_is_custom_true`
- `test_is_pretrained_false`
- `test_supported_input_types_text_and_code`

#### State Transition Tests
- `test_load_sets_initialized`
- `test_unload_clears_initialized`
- `test_unload_when_not_loaded_fails`
- `test_load_twice_is_idempotent`

#### HDC Core Operation Tests
- `test_bind_is_commutative`
- `test_bind_is_self_inverse`
- `test_bundle_single_vector_unchanged`
- `test_bundle_two_vectors_majority`
- `test_bundle_odd_count_no_ties`
- `test_permute_wraps_around`
- `test_permute_zero_unchanged`
- `test_hamming_distance_identical_is_zero`
- `test_hamming_distance_opposite_is_max`
- `test_similarity_identical_is_one`
- `test_similarity_range_zero_to_one`

#### Embedding Tests
- `test_embed_before_load_fails`
- `test_embed_text_returns_1024d`
- `test_embed_code_returns_1024d`
- `test_embed_returns_normalized_vector`
- `test_embed_no_nan_values`
- `test_embed_no_inf_values`
- `test_embed_deterministic_same_input`
- `test_embed_different_inputs_differ`
- `test_embed_model_id_is_hdc`

#### Edge Case Tests (MANDATORY - Print Before/After State)
- `test_edge_case_1_empty_text_content`
- `test_edge_case_2_single_character`
- `test_edge_case_3_max_length_input`
- `test_edge_case_4_unsupported_modality_image`
- `test_edge_case_5_unicode_characters`
- `test_edge_case_6_whitespace_only`

---

## FULL STATE VERIFICATION (MANDATORY)

After completing the implementation, you MUST verify:

### 1. Source of Truth Identification
The source of truth is the `ModelState::Loaded` struct containing:
- `base_vectors: HashMap<char, BitVec<u64, Lsb0>>` - Character → hypervector mapping
- `position_vectors: Vec<BitVec<u64, Lsb0>>` - Position encoding vectors
- `projection_weights: Vec<f32>` - Projection matrix (optional, can use simple grouping)

### 2. Execute & Inspect
```rust
#[tokio::test]
async fn test_source_of_truth_verification() {
    let model = HdcModel::with_seed(Path::new("models/hdc"), SingleModelConfig::default(), 42)
        .expect("Create model");
    model.load().await.expect("Load model");

    let input = ModelInput::text("Hello HDC world").expect("Input");
    let embedding = model.embed(&input).await.expect("Embed");

    // INSPECT SOURCE OF TRUTH
    println!("=== SOURCE OF TRUTH VERIFICATION ===");
    println!("model_id: {:?}", embedding.model_id);
    println!("vector.len(): {}", embedding.vector.len());
    println!("vector[0..10]: {:?}", &embedding.vector[0..10]);
    println!("latency_us: {}", embedding.latency_us);

    let norm: f32 = embedding.vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    println!("L2 norm: {}", norm);

    // VERIFY
    assert_eq!(embedding.model_id, ModelId::Hdc);
    assert_eq!(embedding.vector.len(), 1024);
    assert!(embedding.vector.iter().all(|x| x.is_finite()));
}
```

### 3. Boundary & Edge Case Audit (Print Before/After)
```rust
#[tokio::test]
async fn test_edge_case_1_empty_text_content() {
    println!("=== EDGE CASE 1: Empty Text Content ===");

    let result = ModelInput::text("");
    println!("BEFORE: ModelInput::text(\"\") = {:?}", result.is_err());

    assert!(result.is_err(), "Empty text should fail at ModelInput creation");
    println!("AFTER: Correctly rejected empty input");
}

#[tokio::test]
async fn test_edge_case_2_single_character() {
    let model = create_and_load_model().await;

    println!("=== EDGE CASE 2: Single Character ===");
    println!("BEFORE: model.is_initialized() = {}", model.is_initialized());

    let input = ModelInput::text("X").expect("Single char input");
    let result = model.embed(&input).await;

    println!("AFTER: result.is_ok() = {}", result.is_ok());

    let embedding = result.expect("Single char should embed");
    assert_eq!(embedding.vector.len(), 1024);
    println!("AFTER: vector.len() = {}", embedding.vector.len());
}

#[tokio::test]
async fn test_edge_case_3_max_length_input() {
    let model = create_and_load_model().await;

    println!("=== EDGE CASE 3: Max Length Input (4096 chars) ===");

    let long_text = "A".repeat(HDC_MAX_CHARS + 1000);  // Exceeds limit
    println!("BEFORE: input.len() = {}", long_text.len());

    let input = ModelInput::text(&long_text).expect("Long input");
    let result = model.embed(&input).await;

    println!("AFTER: result.is_ok() = {}", result.is_ok());

    // Should succeed (truncates to HDC_MAX_CHARS internally)
    let embedding = result.expect("Should handle by truncating");
    assert_eq!(embedding.vector.len(), 1024);
    println!("AFTER: vector.len() = {}", embedding.vector.len());
}
```

### 4. Evidence of Success Test
```rust
#[tokio::test]
async fn test_evidence_of_success() {
    println!("\n========================================");
    println!("M03-L11 HDC MODEL EVIDENCE OF SUCCESS");
    println!("========================================\n");

    let model = HdcModel::with_seed(
        Path::new("models/hdc"),
        SingleModelConfig::default(),
        42
    ).expect("Create model");

    // 1. Model metadata
    println!("1. MODEL METADATA:");
    println!("   model_id = {:?}", model.model_id());
    println!("   dimension = {}", model.dimension());
    println!("   projected_dimension = {}", model.projected_dimension());
    println!("   max_tokens = {}", model.max_tokens());
    println!("   is_initialized = {}", model.is_initialized());
    println!("   is_custom = {}", !model.is_pretrained());
    println!("   latency_budget_ms = {}", model.latency_budget_ms());

    // 2. Load and verify state
    model.load().await.expect("Load");
    println!("\n2. POST-LOAD STATE:");
    println!("   is_initialized = {}", model.is_initialized());

    // 3. Embed and verify output
    let input = ModelInput::text("Hello HDC world").expect("Input");
    let start = std::time::Instant::now();
    let embedding = model.embed(&input).await.expect("Embed");
    let elapsed = start.elapsed();

    println!("\n3. EMBEDDING OUTPUT:");
    println!("   input = \"Hello HDC world\"");
    println!("   vector.len() = {}", embedding.vector.len());
    println!("   latency = {:?}", elapsed);
    println!("   vector[0..5] = {:?}", &embedding.vector[0..5]);

    let norm: f32 = embedding.vector.iter().map(|x| x * x).sum::<f32>().sqrt();
    println!("   L2 norm = {}", norm);

    // 4. Determinism check
    println!("\n4. DETERMINISM CHECK:");
    let emb2 = model.embed(&input).await.expect("Embed 2");
    let is_deterministic = embedding.vector == emb2.vector;
    println!("   same input same output = {}", is_deterministic);

    // 5. HDC operations check
    println!("\n5. HDC OPERATIONS:");
    let a = bitvec![u64, Lsb0; 1, 0, 1, 1, 0, 0, 1, 0];
    let b = bitvec![u64, Lsb0; 0, 1, 1, 0, 0, 1, 1, 0];
    let bound = HdcModel::bind(&a, &b);
    println!("   bind([1,0,1,1,0,0,1,0], [0,1,1,0,0,1,1,0]) = {:?}", bound);

    let self_bind = HdcModel::bind(&a, &a);
    let all_zeros = self_bind.count_ones() == 0;
    println!("   bind(A, A) is all zeros = {}", all_zeros);

    println!("\n========================================");
    println!("ALL CHECKS PASSED");
    println!("========================================\n");

    // Assertions
    assert_eq!(embedding.vector.len(), 1024);
    assert!(is_deterministic);
    assert!(all_zeros);
}
```

---

## ANTI-PATTERNS TO AVOID

From constitution.yaml `forbidden` section:
- **AP-001**: No `unwrap()` in production code - use `expect()` with context
- **AP-003**: No magic numbers - use constants (HDC_BIT_DIMENSION, etc.)
- **AP-007**: No stub data in production - tests use deterministic seeded generation
- **AP-009**: No NaN/Infinity - clamp similarity to [0, 1]

---

## NO BACKWARDS COMPATIBILITY

This is a new implementation. There are no existing HDC files to maintain compatibility with. If any test fails, the code is broken and must be fixed - do not create workarounds.

---

## SHERLOCK VERIFICATION (MANDATORY FINAL STEP)

After completing implementation, you MUST spawn a `sherlock-holmes` agent to verify:

1. All 30+ tests pass with `cargo test --lib -p context-graph-embeddings`
2. `mod.rs` correctly exports HdcModel and constants
3. File is at correct path: `crates/context-graph-embeddings/src/models/custom/hdc.rs`
4. No compilation errors or warnings
5. All edge case tests print before/after state
6. Evidence of success test produces complete output
7. HDC operations (bind, bundle, permute, hamming, similarity) are mathematically correct

The sherlock agent must run the actual tests and verify outputs exist in the database/system.

---

## COMPLETION CHECKLIST

- [x] `hdc.rs` created in `crates/context-graph-embeddings/src/models/custom/`
- [x] `mod.rs` updated with `mod hdc; pub use hdc::*;`
- [x] `bitvec` dependency verified in Cargo.toml
- [x] All constants defined (HDC_BIT_DIMENSION, HDC_OUTPUT_DIMENSION, etc.)
- [x] `HdcModel` struct implemented with RwLock<ModelState>
- [x] `bind()` is commutative and self-inverse
- [x] `bundle()` implements majority voting
- [x] `permute()` implements circular rotation
- [x] `hamming_distance()` and `similarity()` implemented
- [x] `encode_string()` uses HRR (bind with position, then bundle)
- [x] `project_to_float()` maps 10K bits → 1024 floats
- [x] `EmbeddingModel` trait fully implemented
- [x] 30+ unit tests written and passing (52 tests)
- [x] 3 edge case tests with before/after state printing
- [x] Source of truth verification test
- [x] Evidence of success test
- [x] Sherlock verification complete
- [x] `cargo test --lib -p context-graph-embeddings` passes

---

*Task Version: 2.0.0 | Updated: 2026-01-01 | Module: M03 Embedding Pipeline*
