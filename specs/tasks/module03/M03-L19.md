<?xml version="1.0" encoding="UTF-8"?>
<task_spec id="M03-L19" version="3.0">
<metadata>
  <title>CacheManager Implementation with LRU Eviction</title>
  <status>COMPLETE</status>
  <layer>logic</layer>
  <sequence>19</sequence>
  <implements>PRD-EMB-003: Embedding Cache System</implements>
  <depends_on>M03-L18 (COMPLETE: 19/19 tests passing)</depends_on>
  <estimated_hours>4</estimated_hours>
  <actual_completion>2026-01-01</actual_completion>
  <tests_passing>66/66 cache tests</tests_passing>
  <sherlock_audit>INNOCENT - all requirements verified</sherlock_audit>
</metadata>

<context>
## IMPLEMENTATION STATUS: COMPLETE

The CacheManager has been fully implemented and verified. This task document now serves as
reference documentation for the implementation at:
`crates/context-graph-embeddings/src/cache/manager.rs` (640 lines implementation + 618 lines tests)

DEPENDENCY STATUS: M03-L18 is COMPLETE. CacheKey and CacheEntry types exist in
`crates/context-graph-embeddings/src/cache/types.rs` with 19 passing tests.

## Key Performance Targets (from constitution.yaml)
- Lookup latency: &lt;100μs (reflex_cache budget)
- Hit rate target: &gt;80% under normal workload
- Max entries: 100,000 (configurable)
- Max bytes: 1GB (configurable)

## Architecture
- LinkedHashMap maintains insertion order for LRU semantics
- RwLock optimizes for read-heavy workloads (multiple concurrent readers)
- Atomic counters provide lock-free metrics updates
- Optional disk persistence uses bincode serialization with xxhash64 checksum
</context>

<source_of_truth>
  <primary>In-memory LinkedHashMap&lt;CacheKey, CacheEntry&gt; wrapped in RwLock</primary>
  <secondary>Optional disk file at configured persistence path (bincode format)</secondary>
  <metrics>CacheMetrics struct with atomic counters for hits/misses/evictions/bytes</metrics>
  <verification_location>crates/context-graph-embeddings/src/cache/manager.rs</verification_location>
</source_of_truth>

<existing_implementation>
## File Structure (ACTUAL - Verified 2026-01-01)

```
crates/context-graph-embeddings/
├── Cargo.toml                    # Dependencies: linked-hash-map = "0.5", bincode = "1.3"
└── src/
    ├── cache/
    │   ├── mod.rs               # Module exports: CacheManager, CacheMetrics, CacheKey, CacheEntry
    │   ├── types.rs             # CacheKey (8-byte xxhash), CacheEntry (embedding wrapper)
    │   └── manager.rs           # CacheManager implementation (THIS TASK)
    ├── config.rs                # CacheConfig (lines 635-700), EvictionPolicy enum
    └── error.rs                 # EmbeddingError::CacheError, EmbeddingResult
```

## CacheConfig (from config.rs lines 635-700)
```rust
pub enum EvictionPolicy {
    Lru,      // Least Recently Used (DEFAULT)
    Lfu,      // Least Frequently Used
    TtlLru,   // TTL with LRU fallback
    Arc,      // Adaptive Replacement Cache
}

pub struct CacheConfig {
    pub enabled: bool,           // Default: true
    pub max_entries: usize,      // Default: 100_000
    pub max_bytes: usize,        // Default: 1GB (1_073_741_824)
    pub ttl_seconds: Option<u64>,// Default: None (no expiration)
    pub eviction_policy: EvictionPolicy, // Default: Lru
    pub persist_to_disk: bool,   // Default: false
    pub disk_path: Option<PathBuf>, // Required if persist_to_disk=true
}
```

## CacheKey and CacheEntry (from types.rs)
```rust
// CacheKey: 8-byte xxhash content hash (u64) - Copy, Eq, Hash
pub struct CacheKey { pub content_hash: u64 }
impl CacheKey {
    pub fn from_content(content: &str) -> Self;
    pub fn from_input(input: &ModelInput) -> Self;
    pub fn from_embedding(embedding: &FusedEmbedding) -> Self;
}

// CacheEntry: embedding wrapper with access tracking
pub struct CacheEntry {
    pub embedding: FusedEmbedding,
    created_at: Instant,
    last_accessed: AtomicU64,
    access_count: AtomicU32,
}
impl CacheEntry {
    pub fn new(embedding: FusedEmbedding) -> Self;
    pub fn memory_size(&self) -> usize;  // ~6226 bytes per entry
    pub fn is_expired(&self, ttl: Duration) -> bool;
    pub fn touch(&self);                  // Update last_accessed (LRU)
    pub fn increment_access(&self);       // Increment count (LFU)
}
```
</existing_implementation>

<implemented_api>
## CacheMetrics (manager.rs lines 84-135)
```rust
pub struct CacheMetrics {
    pub hits: AtomicU64,
    pub misses: AtomicU64,
    pub evictions: AtomicU64,
    pub bytes_used: AtomicUsize,
}
impl CacheMetrics {
    pub fn new() -> Self;
    pub fn reset(&self);
    pub fn record_hit(&self);
    pub fn record_miss(&self);
    pub fn record_eviction(&self);
    pub fn add_bytes(&self, bytes: usize);
    pub fn subtract_bytes(&self, bytes: usize);
}
```

## CacheManager (manager.rs lines 137-639)
```rust
pub struct CacheManager {
    entries: RwLock<LinkedHashMap<CacheKey, CacheEntry>>,
    config: CacheConfig,
    metrics: CacheMetrics,
}

impl CacheManager {
    /// Create new cache manager. ERRORS on invalid config.
    pub fn new(config: CacheConfig) -> EmbeddingResult<Self>;

    /// Get embedding by key, updating LRU order. Returns None if expired/missing.
    pub fn get(&self, key: &CacheKey) -> Option<FusedEmbedding>;

    /// Insert embedding, evicting LRU entries if needed.
    pub fn put(&self, key: CacheKey, embedding: FusedEmbedding) -> EmbeddingResult<()>;

    /// Check if key exists (does NOT update LRU order or check TTL).
    pub fn contains(&self, key: &CacheKey) -> bool;

    /// Remove entry by key.
    pub fn remove(&self, key: &CacheKey) -> Option<FusedEmbedding>;

    /// Clear all entries, reset metrics.
    pub fn clear(&self);

    /// Current entry count.
    pub fn len(&self) -> usize;

    /// Check if cache is empty.
    pub fn is_empty(&self) -> bool;

    /// Calculate hit rate: hits / (hits + misses). Returns 0.0 if no accesses.
    pub fn hit_rate(&self) -> f32;

    /// Current memory usage in bytes.
    pub fn memory_usage(&self) -> usize;

    /// Get reference to cache metrics.
    pub fn metrics(&self) -> &CacheMetrics;

    /// Get reference to cache configuration.
    pub fn config(&self) -> &CacheConfig;

    /// Persist cache to disk (async). ERRORS on I/O or serialization failure.
    pub async fn persist(&self) -> EmbeddingResult<()>;

    /// Load cache from disk (async). ERRORS on I/O, deserialization, or checksum mismatch.
    pub async fn load(&self) -> EmbeddingResult<()>;
}
```
</implemented_api>

<implementation_details>
## LRU Algorithm
- `get()` uses `LinkedHashMap::get_refresh()` to move entry to END (most recently used)
- `evict_oldest()` uses `pop_front()` to remove from FRONT (least recently used)
- TRUE LRU: Access moves entry to back, not just insertion order

## TTL Expiration
- Checked lazily in `get()` when `ttl_seconds` is configured
- Expired entries are removed and recorded as misses
- `contains()` does NOT check TTL (use `get()` for validity check)

## Memory Eviction
1. Check if single entry exceeds max_bytes → return Err immediately
2. Evict oldest entries until under max_entries limit
3. Evict oldest entries until under max_bytes limit

## Disk Persistence Format
```
Header:  [0x43, 0x47, 0x45, 0x43] (magic "CGEC") + version(u8) + entry_count(u64)
Body:    bincode-serialized Vec<SerializableCacheEntry>
Footer:  xxhash64 checksum (u64)
```

## Thread Safety
- RwLock for entries (read-heavy optimization)
- Atomic counters for metrics (lock-free statistics)
- Lock poison handled gracefully (returns None/0/false, logs error)

## Error Handling (FAIL-FAST)
- All errors logged with `tracing::error!` BEFORE returning Err
- No `unwrap()` or `expect()` in production code (constitution.yaml compliance)
- Uses `?` operator and `map_err()` for error propagation
</implementation_details>

<test_coverage>
## Test Results (66 tests passing)
```bash
cargo test -p context-graph-embeddings cache -- --nocapture
# test result: ok. 66 passed; 0 failed
```

### CacheManager Tests (23 tests)
- test_new_with_valid_config
- test_new_with_zero_max_entries_fails
- test_new_with_zero_max_bytes_fails
- test_new_with_persist_but_no_path_fails
- test_put_get_roundtrip
- test_get_nonexistent_key_returns_none
- test_lru_eviction_at_max_entries
- test_lru_access_prevents_eviction (TRUE LRU behavior)
- test_max_entries_limit_enforced
- test_max_bytes_limit_enforced
- test_ttl_expiration_returns_none
- test_ttl_valid_entry_returned
- test_hit_rate_calculation
- test_hit_rate_zero_when_no_accesses
- test_contains_key
- test_remove_entry
- test_clear
- test_persist_load_roundtrip
- test_persist_without_path_fails
- test_load_detects_checksum_mismatch
- test_put_oversized_entry_fails
- test_update_existing_key
- test_memory_tracking_accuracy

### CacheEntry/CacheKey Tests (19 tests in types.rs)
- CacheKey hashing, equality, from_content, from_input, from_embedding
- CacheEntry creation, touch, increment_access, is_expired, memory_size
</test_coverage>

<sherlock_audit_results>
## Forensic Audit: INNOCENT (2026-01-01)

### Method Coverage: 12/12 VERIFIED
All required methods present with correct signatures.

### Fail-Fast Violations: NONE
Zero unwrap()/expect() in production code (all in #[cfg(test)]).

### LRU Correctness: VERIFIED
- get() uses get_refresh() → moves to END
- evict_oldest() uses pop_front() → removes from FRONT

### Memory Tracking: VERIFIED
- put(): add_bytes
- remove(): subtract_bytes
- eviction: subtract_bytes
- clear(): reset()

### Checksum Validation: VERIFIED
Both persist() and load() use xxhash64.

### Error Logging: 19/19 paths VERIFIED
All error paths log with tracing::error! before returning Err.

### CacheEntry Integration: VERIFIED
6 locations correctly use CacheEntry::memory_size().
</sherlock_audit_results>

<full_state_verification>
## Source of Truth
The cache state is stored in `CacheManager.entries` (LinkedHashMap) and metrics in `CacheManager.metrics`.

## Verification Commands
```bash
# Run all cache tests with output
cargo test -p context-graph-embeddings cache -- --nocapture

# Run specific edge case tests
cargo test -p context-graph-embeddings test_lru_access_prevents_eviction -- --nocapture
cargo test -p context-graph-embeddings test_persist_load_roundtrip -- --nocapture
cargo test -p context-graph-embeddings test_load_detects_checksum_mismatch -- --nocapture

# Check clippy warnings
cargo clippy -p context-graph-embeddings -- -D warnings
```

## Edge Case Audit Results

### EC1: Empty Cache Get
- **Before**: entries.len() == 0, metrics.misses == 0
- **Action**: cache.get(&CacheKey(12345))
- **After**: Returns None, metrics.misses == 1
- **Verified**: test_get_nonexistent_key_returns_none

### EC2: Put at Max Capacity
- **Before**: entries.len() == max_entries, oldest_key = first entry
- **Action**: cache.put(new_key, new_embedding)
- **After**: entries.len() == max_entries, oldest evicted, new_key present
- **Verified**: test_lru_eviction_at_max_entries

### EC3: TRUE LRU Behavior (Access Prevents Eviction)
- **Before**: Insert A, B, C (A is oldest)
- **Action**: cache.get(&A) then cache.put(D)
- **After**: B evicted (not A), because A was accessed (moved to back)
- **Verified**: test_lru_access_prevents_eviction

### EC4: TTL Expiration
- **Before**: Entry exists with created_at 50ms ago, ttl=10ms
- **Action**: cache.get(&key)
- **After**: Returns None, entry removed, metrics.misses += 1
- **Verified**: test_ttl_expiration_returns_none

### EC5: Checksum Mismatch
- **Before**: Corrupted cache file with wrong checksum
- **Action**: cache.load()
- **After**: Returns Err(CacheError), cache unchanged
- **Verified**: test_load_detects_checksum_mismatch
</full_state_verification>

<evidence_of_success>
## Test Output Log (Actual)
```
test cache::manager::tests::test_put_get_roundtrip ...
BEFORE: Creating cache and inserting embedding
AFTER: Cache state: len=1, bytes=6226
PASSED: put/get round-trip preserves embedding data

test cache::manager::tests::test_lru_access_prevents_eviction ...
BEFORE: Creating cache with max_entries=3 for LRU access test
AFTER insert A,B,C: len=3
AFTER access A: A moved to back of LRU order
AFTER insert D: len=3, evictions=1
PASSED: LRU access prevents eviction - A survived, B was evicted

test cache::manager::tests::test_persist_load_roundtrip ...
BEFORE: Creating cache with persistence at "/tmp/.tmpXXXX/cache.bin"
BEFORE persist: len=2
AFTER persist: file exists = true
AFTER load: len=2
PASSED: persist/load round-trip preserves all entries

test result: ok. 66 passed; 0 failed
```

## Memory Tracking Evidence
```
test cache::manager::tests::test_memory_tracking_accuracy ...
AFTER put: expected_size=6226, actual_usage=6226
AFTER remove: usage=0
PASSED: Memory tracking is accurate
```
</evidence_of_success>

<validation_criteria>
  <criterion id="V1" status="PASSED">cargo check passes</criterion>
  <criterion id="V2" status="PASSED">cargo clippy passes without warnings</criterion>
  <criterion id="V3" status="PASSED">Unit test: put/get round-trip works correctly</criterion>
  <criterion id="V4" status="PASSED">Unit test: LRU eviction removes oldest entry first</criterion>
  <criterion id="V5" status="PASSED">Unit test: max_entries limit enforced</criterion>
  <criterion id="V6" status="PASSED">Unit test: max_bytes limit enforced</criterion>
  <criterion id="V7" status="PASSED">Unit test: TTL expiration returns None for expired entries</criterion>
  <criterion id="V8" status="PASSED">Unit test: hit_rate calculation accurate</criterion>
  <criterion id="V9" status="PASSED">Integration test: persist/load round-trip preserves all entries</criterion>
  <criterion id="V10" status="PENDING">Benchmark: get() latency &lt;100μs (requires criterion bench)</criterion>
</validation_criteria>

<future_work>
## Remaining for Production
1. **Benchmark Tests**: Add criterion benchmarks to validate &lt;100μs lookup latency
2. **LFU/ARC/TtlLru Policies**: Currently only LRU is implemented
3. **Async Eviction**: Background cleanup for large caches
4. **Sharding**: For >1M entries, consider sharded cache

## Next Task
M03-L20: GatingNetwork for FuseMoE (depends on M03-F02, M03-F14)
</future_work>

</task_spec>
