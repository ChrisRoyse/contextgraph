# M05-T25: Create Module Integration Tests and Benchmarks

```yaml
metadata:
  id: "M05-T25"
  title: "Create Module Integration Tests and Benchmarks"
  module: "module-05"
  module_name: "UTL Integration"
  layer: "surface"
  priority: "critical"
  estimated_hours: 5
  created: "2026-01-04"
  status: "pending"
  dependencies:
    - "M05-T22"
    - "M05-T24"
  spec_refs:
    - "TECH-UTL-005 Section 12"
    - "SPEC-UTL-005 Section 12, 13"
```

## Description

Implement comprehensive integration tests for Module 5:
- Full UTL pipeline with real data (no mocks)
- Learning signal correlation with importance (r > 0.7)
- Lifecycle stage transitions at correct thresholds
- Lambda weight application verification
- Johari quadrant classification correctness
- NaN/Infinity prevention tests
- Emotional weight bounds [0.5, 1.5]

Benchmark tests:
- compute_learning_magnitude: <100us
- Full UTL computation: <10ms
- Surprise calculation: <5ms
- Emotional weight: <1ms

## File Locations

| Type | Path |
|------|------|
| Test File | `crates/context-graph-utl/tests/integration_tests.rs` |
| Benchmark File | `crates/context-graph-utl/benches/utl_bench.rs` |

## Acceptance Criteria

- [ ] All unit tests pass
- [ ] Integration test covers full pipeline
- [ ] Correlation test validates r > 0.7
- [ ] Lifecycle transitions verified
- [ ] Lambda weights correct per stage
- [ ] Johari classification matches spec table
- [ ] No NaN/Infinity in any test
- [ ] Benchmark meets performance targets
- [ ] 90%+ code coverage

## Technical Requirements

### Integration Test Structure

```rust
// crates/context-graph-utl/tests/integration_tests.rs

use context_graph_utl::{
    UtlProcessor, UtlConfig, LearningSignal,
    LifecycleStage, JohariQuadrant, LifecycleLambdaWeights
};

#[cfg(test)]
mod integration_tests {
    use super::*;

    /// Full UTL pipeline test with real data (no mocks)
    #[test]
    fn test_full_utl_pipeline() {
        let config = UtlConfig::default();
        let processor = UtlProcessor::new(config);

        // Generate realistic test embeddings
        let embedding = generate_test_embedding(1536);
        let context_embeddings = generate_context_embeddings(50, 1536);
        let content = "Test content for emotional analysis";

        let signal = processor.compute_learning(&embedding, &context_embeddings, content);

        // Validate output constraints
        assert!(signal.magnitude >= 0.0 && signal.magnitude <= 1.0);
        assert!(signal.delta_s >= 0.0 && signal.delta_s <= 1.0);
        assert!(signal.delta_c >= 0.0 && signal.delta_c <= 1.0);
        assert!(signal.w_e >= 0.5 && signal.w_e <= 1.5);
        assert!(signal.phi >= 0.0 && signal.phi <= std::f32::consts::PI);
    }

    /// Learning signal correlation with importance must exceed r > 0.7
    #[test]
    fn test_learning_importance_correlation() {
        let processor = UtlProcessor::new(UtlConfig::default());

        // Generate test cases with varying importance
        let test_cases: Vec<(f32, f32)> = (0..100)
            .map(|i| {
                let importance = i as f32 / 100.0;
                // Higher importance should correlate with higher learning magnitude
                // when surprise and coherence conditions are met
                (importance, /* computed magnitude */ 0.0)
            })
            .collect();

        let correlation = compute_pearson_correlation(&test_cases);
        assert!(correlation > 0.7, "Correlation {} must exceed 0.7", correlation);
    }

    /// Lifecycle stage transitions at correct thresholds
    #[test]
    fn test_lifecycle_transitions() {
        let config = UtlConfig::default();
        let mut processor = UtlProcessor::new(config);

        // Initial state should be Infancy
        assert_eq!(processor.get_status().lifecycle_stage, LifecycleStage::Infancy);

        // Simulate 50 interactions -> Growth
        for _ in 0..50 {
            processor.record_interaction();
        }
        assert_eq!(processor.get_status().lifecycle_stage, LifecycleStage::Growth);

        // Simulate 450 more interactions (total 500) -> Maturity
        for _ in 0..450 {
            processor.record_interaction();
        }
        assert_eq!(processor.get_status().lifecycle_stage, LifecycleStage::Maturity);
    }

    /// Lambda weight application verification per lifecycle stage
    #[test]
    fn test_lambda_weights_per_stage() {
        // Infancy: lambda_novelty=0.7, lambda_consolidation=0.3
        let infancy_weights = LifecycleStage::Infancy.get_lambda_weights();
        assert!((infancy_weights.lambda_novelty - 0.7).abs() < 0.001);
        assert!((infancy_weights.lambda_consolidation - 0.3).abs() < 0.001);

        // Growth: lambda_novelty=0.5, lambda_consolidation=0.5
        let growth_weights = LifecycleStage::Growth.get_lambda_weights();
        assert!((growth_weights.lambda_novelty - 0.5).abs() < 0.001);
        assert!((growth_weights.lambda_consolidation - 0.5).abs() < 0.001);

        // Maturity: lambda_novelty=0.3, lambda_consolidation=0.7
        let maturity_weights = LifecycleStage::Maturity.get_lambda_weights();
        assert!((maturity_weights.lambda_novelty - 0.3).abs() < 0.001);
        assert!((maturity_weights.lambda_consolidation - 0.7).abs() < 0.001);
    }

    /// Johari quadrant classification correctness
    #[test]
    fn test_johari_classification() {
        let classifier = JohariClassifier::new(JohariConfig::default());

        // Low entropy, high coherence -> Open
        assert_eq!(classifier.classify(0.2, 0.8), JohariQuadrant::Open);

        // High entropy, low coherence -> Blind
        assert_eq!(classifier.classify(0.8, 0.2), JohariQuadrant::Blind);

        // Low entropy, low coherence -> Hidden
        assert_eq!(classifier.classify(0.2, 0.2), JohariQuadrant::Hidden);

        // High entropy, high coherence -> Unknown
        assert_eq!(classifier.classify(0.8, 0.8), JohariQuadrant::Unknown);
    }

    /// NaN/Infinity prevention tests
    #[test]
    fn test_nan_infinity_prevention() {
        let processor = UtlProcessor::new(UtlConfig::default());

        // Edge case: empty context
        let signal = processor.compute_learning(&[0.0; 1536], &[], "");
        assert!(!signal.magnitude.is_nan());
        assert!(!signal.magnitude.is_infinite());

        // Edge case: zero embedding
        let signal = processor.compute_learning(&[0.0; 1536], &[[0.0; 1536]], "");
        assert!(!signal.delta_s.is_nan());
        assert!(!signal.delta_c.is_nan());

        // Edge case: extreme values
        let signal = processor.compute_learning(&[f32::MAX; 1536], &[[f32::MIN; 1536]], "!!!!");
        assert!(!signal.w_e.is_nan());
        assert!(!signal.phi.is_nan());
    }

    /// Emotional weight bounds [0.5, 1.5]
    #[test]
    fn test_emotional_weight_bounds() {
        let calculator = EmotionalWeightCalculator::new(EmotionalConfig::default());

        // Neutral content
        let neutral = calculator.compute_weight("This is a neutral statement.");
        assert!(neutral >= 0.5 && neutral <= 1.5);

        // Positive content
        let positive = calculator.compute_weight("EXCELLENT! This is WONDERFUL and AMAZING!!!");
        assert!(positive >= 0.5 && positive <= 1.5);
        assert!(positive > neutral); // Should be higher

        // Negative content
        let negative = calculator.compute_weight("ERROR! CRITICAL FAILURE! DANGER!");
        assert!(negative >= 0.5 && negative <= 1.5);
    }
}

// Helper functions
fn generate_test_embedding(dim: usize) -> Vec<f32> {
    (0..dim).map(|i| ((i as f32).sin() + 1.0) / 2.0).collect()
}

fn generate_context_embeddings(count: usize, dim: usize) -> Vec<Vec<f32>> {
    (0..count).map(|_| generate_test_embedding(dim)).collect()
}

fn compute_pearson_correlation(pairs: &[(f32, f32)]) -> f32 {
    // Pearson correlation coefficient implementation
    let n = pairs.len() as f32;
    let sum_x: f32 = pairs.iter().map(|(x, _)| x).sum();
    let sum_y: f32 = pairs.iter().map(|(_, y)| y).sum();
    let sum_xy: f32 = pairs.iter().map(|(x, y)| x * y).sum();
    let sum_x2: f32 = pairs.iter().map(|(x, _)| x * x).sum();
    let sum_y2: f32 = pairs.iter().map(|(_, y)| y * y).sum();

    let numerator = n * sum_xy - sum_x * sum_y;
    let denominator = ((n * sum_x2 - sum_x * sum_x) * (n * sum_y2 - sum_y * sum_y)).sqrt();

    if denominator == 0.0 { 0.0 } else { numerator / denominator }
}
```

### Benchmark Structure

```rust
// crates/context-graph-utl/benches/utl_bench.rs

use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};
use context_graph_utl::{
    compute_learning_magnitude, UtlProcessor, UtlConfig,
    SurpriseCalculator, SurpriseConfig,
    EmotionalWeightCalculator, EmotionalConfig,
};

fn bench_compute_learning_magnitude(c: &mut Criterion) {
    c.bench_function("compute_learning_magnitude", |b| {
        b.iter(|| {
            compute_learning_magnitude(
                black_box(0.6),  // delta_s
                black_box(0.7),  // delta_c
                black_box(1.2),  // w_e
                black_box(1.0),  // phi
            )
        })
    });
}

fn bench_full_utl_computation(c: &mut Criterion) {
    let config = UtlConfig::default();
    let processor = UtlProcessor::new(config);
    let embedding: Vec<f32> = (0..1536).map(|i| (i as f32).sin()).collect();
    let context: Vec<Vec<f32>> = (0..50)
        .map(|_| (0..1536).map(|i| (i as f32).cos()).collect())
        .collect();
    let content = "Test content for UTL computation";

    c.bench_function("full_utl_computation", |b| {
        b.iter(|| {
            processor.compute_learning(
                black_box(&embedding),
                black_box(&context),
                black_box(content),
            )
        })
    });
}

fn bench_surprise_calculation(c: &mut Criterion) {
    let config = SurpriseConfig::default();
    let calculator = SurpriseCalculator::new(config);
    let observed: Vec<f32> = (0..1536).map(|i| (i as f32).sin()).collect();
    let context: Vec<Vec<f32>> = (0..50)
        .map(|_| (0..1536).map(|i| (i as f32).cos()).collect())
        .collect();

    c.bench_function("surprise_calculation", |b| {
        b.iter(|| {
            calculator.compute_surprise_ensemble(
                black_box(&observed),
                black_box(&context),
            )
        })
    });
}

fn bench_emotional_weight(c: &mut Criterion) {
    let config = EmotionalConfig::default();
    let calculator = EmotionalWeightCalculator::new(config);
    let content = "EXCELLENT! This is an amazing and wonderful test content!!!";

    c.bench_function("emotional_weight", |b| {
        b.iter(|| {
            calculator.compute_weight(black_box(content))
        })
    });
}

fn bench_context_sizes(c: &mut Criterion) {
    let config = UtlConfig::default();
    let processor = UtlProcessor::new(config);
    let embedding: Vec<f32> = (0..1536).map(|i| (i as f32).sin()).collect();
    let content = "Test content";

    let mut group = c.benchmark_group("utl_context_scaling");
    for size in [10, 25, 50, 100].iter() {
        let context: Vec<Vec<f32>> = (0..*size)
            .map(|_| (0..1536).map(|i| (i as f32).cos()).collect())
            .collect();

        group.bench_with_input(
            BenchmarkId::from_parameter(size),
            &context,
            |b, ctx| {
                b.iter(|| processor.compute_learning(&embedding, ctx, content))
            },
        );
    }
    group.finish();
}

criterion_group!(
    benches,
    bench_compute_learning_magnitude,
    bench_full_utl_computation,
    bench_surprise_calculation,
    bench_emotional_weight,
    bench_context_sizes,
);
criterion_main!(benches);
```

### Performance Targets

| Function | Target | Measurement |
|----------|--------|-------------|
| `compute_learning_magnitude` | <100us | Mean latency |
| Full UTL computation | <10ms | P99 latency |
| Surprise calculation | <5ms | P99 latency |
| Emotional weight | <1ms | Mean latency |

### Coverage Requirements

- Minimum 90% line coverage
- 100% coverage of public API
- All error paths tested
- All edge cases documented

## Dependencies

### Required Tasks
- M05-T22: UtlProcessor Main Orchestrator
- M05-T24: UtlMetrics and UtlStatus Structs

### Required Crates
```toml
[dev-dependencies]
criterion = "0.5"
proptest = "1.0"
test-case = "3.0"
```

## Verification

```bash
# Run integration tests
cargo test --package context-graph-utl --test integration_tests

# Run benchmarks
cargo bench --package context-graph-utl

# Check coverage
cargo llvm-cov --package context-graph-utl --html
```

## Notes

- All tests must use real data, no mocks for integration tests
- Benchmarks run on CI for regression detection
- Performance regressions >10% should fail CI
- Coverage report generated on each PR
