{
  "timestamp": "2026-01-27T00:17:54.660116344+00:00",
  "model": "Hermes-2-Pro-Mistral-7B.Q5_K_M.gguf",
  "total_pairs": 53,
  "overall_accuracy": 0.6792452830188679,
  "overall_avg_confidence": 0.8018868,
  "domain_results": {
    "negative": {
      "domain": "negative",
      "total_pairs": 10,
      "correct": 10,
      "accuracy": 1.0,
      "domain_detection_correct": 10,
      "domain_detection_accuracy": 1.0,
      "avg_confidence": 0.5,
      "avg_inference_time_ms": 2421.4,
      "relationship_breakdown": {
        "none": {
          "correct": 10,
          "total": 10,
          "accuracy": 1.0,
          "avg_confidence": 0.5,
          "confidences": [
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5,
            0.5
          ]
        }
      }
    },
    "general": {
      "domain": "general",
      "total_pairs": 8,
      "correct": 3,
      "accuracy": 0.375,
      "domain_detection_correct": 7,
      "domain_detection_accuracy": 0.875,
      "avg_confidence": 0.84999996,
      "avg_inference_time_ms": 2337.125,
      "relationship_breakdown": {
        "contains": {
          "correct": 1,
          "total": 2,
          "accuracy": 0.5,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "references": {
          "correct": 1,
          "total": 2,
          "accuracy": 0.5,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "depends_on": {
          "correct": 0,
          "total": 2,
          "accuracy": 0.0,
          "avg_confidence": 0.7,
          "confidences": [
            0.7,
            0.7
          ]
        },
        "modifies": {
          "correct": 1,
          "total": 2,
          "accuracy": 0.5,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        }
      }
    },
    "code": {
      "domain": "code",
      "total_pairs": 10,
      "correct": 7,
      "accuracy": 0.7,
      "domain_detection_correct": 9,
      "domain_detection_accuracy": 0.9,
      "avg_confidence": 0.82000005,
      "avg_inference_time_ms": 2203.3,
      "relationship_breakdown": {
        "contains": {
          "correct": 0,
          "total": 1,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        },
        "implements": {
          "correct": 1,
          "total": 1,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        },
        "references": {
          "correct": 0,
          "total": 1,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        },
        "calls": {
          "correct": 0,
          "total": 1,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        },
        "none": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.5,
          "confidences": [
            0.5,
            0.5
          ]
        },
        "imports": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "extends": {
          "correct": 1,
          "total": 1,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        },
        "depends_on": {
          "correct": 1,
          "total": 1,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9
          ]
        }
      }
    },
    "legal": {
      "domain": "legal",
      "total_pairs": 15,
      "correct": 10,
      "accuracy": 0.6666666666666666,
      "domain_detection_correct": 13,
      "domain_detection_accuracy": 0.8666666666666667,
      "avg_confidence": 0.89999986,
      "avg_inference_time_ms": 2493.9333333333334,
      "relationship_breakdown": {
        "supersedes": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "distinguishes": {
          "correct": 1,
          "total": 2,
          "accuracy": 0.5,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "cites": {
          "correct": 3,
          "total": 3,
          "accuracy": 1.0,
          "avg_confidence": 0.8999999,
          "confidences": [
            0.9,
            0.9,
            0.9
          ]
        },
        "complies_with": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "overrules": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "applies": {
          "correct": 0,
          "total": 2,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "interprets": {
          "correct": 0,
          "total": 2,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        }
      }
    },
    "academic": {
      "domain": "academic",
      "total_pairs": 10,
      "correct": 6,
      "accuracy": 0.6,
      "domain_detection_correct": 10,
      "domain_detection_accuracy": 1.0,
      "avg_confidence": 0.9,
      "avg_inference_time_ms": 2299.6,
      "relationship_breakdown": {
        "cites": {
          "correct": 3,
          "total": 3,
          "accuracy": 1.0,
          "avg_confidence": 0.8999999,
          "confidences": [
            0.9,
            0.9,
            0.9
          ]
        },
        "applies": {
          "correct": 1,
          "total": 3,
          "accuracy": 0.3333333333333333,
          "avg_confidence": 0.8999999,
          "confidences": [
            0.9,
            0.9,
            0.9
          ]
        },
        "extends": {
          "correct": 2,
          "total": 2,
          "accuracy": 1.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        },
        "references": {
          "correct": 0,
          "total": 2,
          "accuracy": 0.0,
          "avg_confidence": 0.9,
          "confidences": [
            0.9,
            0.9
          ]
        }
      }
    }
  },
  "cross_domain_false_positive_rate": 0.0,
  "latency": {
    "p50_ms": 2255,
    "p95_ms": 3070,
    "p99_ms": 3108,
    "min_ms": 1727,
    "max_ms": 3796,
    "avg_ms": 2365.0754716981132
  },
  "relationship_type_breakdown": {
    "imports": {
      "correct": 2,
      "total": 2,
      "accuracy": 1.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "implements": {
      "correct": 1,
      "total": 1,
      "accuracy": 1.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9
      ]
    },
    "contains": {
      "correct": 1,
      "total": 3,
      "accuracy": 0.3333333333333333,
      "avg_confidence": 0.8999999,
      "confidences": [
        0.9,
        0.9,
        0.9
      ]
    },
    "applies": {
      "correct": 1,
      "total": 5,
      "accuracy": 0.2,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
      ]
    },
    "complies_with": {
      "correct": 2,
      "total": 2,
      "accuracy": 1.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "none": {
      "correct": 12,
      "total": 12,
      "accuracy": 1.0,
      "avg_confidence": 0.5,
      "confidences": [
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
      ]
    },
    "interprets": {
      "correct": 0,
      "total": 2,
      "accuracy": 0.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "depends_on": {
      "correct": 1,
      "total": 3,
      "accuracy": 0.3333333333333333,
      "avg_confidence": 0.76666665,
      "confidences": [
        0.9,
        0.7,
        0.7
      ]
    },
    "calls": {
      "correct": 0,
      "total": 1,
      "accuracy": 0.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9
      ]
    },
    "overrules": {
      "correct": 2,
      "total": 2,
      "accuracy": 1.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "cites": {
      "correct": 6,
      "total": 6,
      "accuracy": 1.0,
      "avg_confidence": 0.90000004,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
      ]
    },
    "supersedes": {
      "correct": 2,
      "total": 2,
      "accuracy": 1.0,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "modifies": {
      "correct": 1,
      "total": 2,
      "accuracy": 0.5,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "distinguishes": {
      "correct": 1,
      "total": 2,
      "accuracy": 0.5,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9
      ]
    },
    "extends": {
      "correct": 3,
      "total": 3,
      "accuracy": 1.0,
      "avg_confidence": 0.8999999,
      "confidences": [
        0.9,
        0.9,
        0.9
      ]
    },
    "references": {
      "correct": 1,
      "total": 5,
      "accuracy": 0.2,
      "avg_confidence": 0.9,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
      ]
    }
  },
  "category_breakdown": {
    "reference": {
      "correct": 8,
      "total": 15,
      "accuracy": 0.5333333333333333,
      "avg_confidence": 0.89999986,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
      ]
    },
    "implementation": {
      "correct": 3,
      "total": 3,
      "accuracy": 1.0,
      "avg_confidence": 0.8999999,
      "confidences": [
        0.9,
        0.9,
        0.9
      ]
    },
    "invocation": {
      "correct": 13,
      "total": 18,
      "accuracy": 0.7222222222222222,
      "avg_confidence": 0.6333333,
      "confidences": [
        0.9,
        0.5,
        0.5,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5,
        0.5
      ]
    },
    "containment": {
      "correct": 1,
      "total": 3,
      "accuracy": 0.3333333333333333,
      "avg_confidence": 0.8999999,
      "confidences": [
        0.9,
        0.9,
        0.9
      ]
    },
    "dependency": {
      "correct": 3,
      "total": 5,
      "accuracy": 0.6,
      "avg_confidence": 0.82,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.7,
        0.7
      ]
    },
    "extension": {
      "correct": 8,
      "total": 9,
      "accuracy": 0.8888888888888888,
      "avg_confidence": 0.90000004,
      "confidences": [
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9,
        0.9
      ]
    }
  },
  "model_load_time_sec": 2.05753208,
  "total_benchmark_time_sec": 125.377099823
}